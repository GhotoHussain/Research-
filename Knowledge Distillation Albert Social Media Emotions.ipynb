{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "\n",
    "import numpy as np # type: ignore # linear algebra\n",
    "import pandas as pd # type: ignore # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emo_la={0:'neutral',1:'Happy',2:'sad',3:'anger',4:'surprise'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a classification label, with possible values including sadness (0), joy (1), love (2), anger (3), fear (4),surprise(5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "emo_la[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory_Data_Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your data is in a CSV file\n",
    "df = pd.read_csv('Dataset name')\n",
    "\n",
    "# Rename Columns\n",
    "df.rename(columns={'text': 'Text', 'label': 'Label'}, inplace=True)\n",
    "\n",
    "# Dropping the Index Column if it exists\n",
    "if 'Unnamed: 0' in df.columns:\n",
    "    df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "# Replace Label values\n",
    "#label_mapping = {0:'neutral',1:'Happy',2:'sad',3:'anger',4:'surprise'}\n",
    "#df['Label'] = df['Label'].replace(label_mapping)\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify changes\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check column names to ensure 'text' or 'Text' exists\n",
    "print(df.columns)\n",
    "\n",
    "# Locate duplicate text\n",
    "# Replace 'text' with the correct column name if necessary\n",
    "duplicated_texts = df[df.duplicated(subset='Text', keep=False)].sort_values(by='Text')\n",
    "\n",
    "# If there is duplicate text, process it\n",
    "if not duplicated_texts.empty:\n",
    "    # Keep only the 'Text' and 'Label' columns\n",
    "    duplicated_texts = duplicated_texts[['Text', 'Label']]\n",
    "    \n",
    "    # Drop duplicates in the 'Text' column, keeping the first occurrence\n",
    "    duplicated_texts = duplicated_texts.drop_duplicates(subset='Text', keep='first')\n",
    "    \n",
    "    # Drop the duplicate rows from the original DataFrame\n",
    "    df = df.drop(duplicated_texts.index)\n",
    "    \n",
    "    # Reset the index of the DataFrame\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Check if there are any texts with multiple labels after processing\n",
    "duplicated_texts = df[df.duplicated(subset='Text', keep=False)].sort_values(by='Text')\n",
    "if not duplicated_texts.empty:\n",
    "    print(\"Texts with multiple labels:\")\n",
    "    print(duplicated_texts[['Text', 'Label']])\n",
    "else:\n",
    "    print(\"No duplicate text was found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming your data is already loaded into a DataFrame called `df`\n",
    "# If not, load your data as shown in the previous example\n",
    "\n",
    "# Value Count of Label\n",
    "count = df['Label'].value_counts()\n",
    "\n",
    "# Create a figure with two subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 6), facecolor='white')\n",
    "\n",
    "# Plot pie chart on the first subplot\n",
    "palette = sns.color_palette(\"viridis\")\n",
    "sns.set_palette(palette)\n",
    "axs[0].pie(count, labels=count.index, autopct='%1.1f%%', startangle=140, colors=palette)\n",
    "axs[0].set_title('Distribution of Emotion Classes', fontsize=14)\n",
    "\n",
    "# Plot bar chart on the second subplot\n",
    "sns.barplot(x=count.index, y=count.values, hue=count.index, palette=\"viridis\", ax=axs[1], legend=False)\n",
    "axs[1].set_title('Distribution of Emotion Classes', fontsize=14)\n",
    "axs[1].set_xlabel('Emotion Classes', fontsize=12)\n",
    "axs[1].set_ylabel('Count', fontsize=12)\n",
    "axs[1].tick_params(axis='x', rotation=45)  # Rotate x-axis labels for better readability\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming your data is already loaded into a DataFrame called `df`\n",
    "# If not, load your data as shown in the previous example\n",
    "\n",
    "# Function to count words in a text\n",
    "def count_words(text):\n",
    "    return len(text.split())\n",
    "\n",
    "# Apply the word count function to the 'Text' column\n",
    "df['Word_Count'] = df['Text'].apply(count_words)\n",
    "\n",
    "# Group by 'Label' and sum the word counts\n",
    "word_count_per_class = df.groupby('Label')['Word_Count'].sum().reset_index()\n",
    "\n",
    "# Display the word count per class\n",
    "print(word_count_per_class)\n",
    "\n",
    "# Plot the word count per class\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Label', y='Word_Count', hue='Label', data=word_count_per_class, palette='viridis', legend=False)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Emotion Classes', fontsize=14)\n",
    "plt.ylabel('Total Word Count', fontsize=14)\n",
    "plt.title('Total Word Count per Emotion Class', fontsize=16)\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Assuming your data is already loaded into a DataFrame called `df`\n",
    "# If not, load your data as shown in the previous example\n",
    "\n",
    "# Function to count words in a text\n",
    "def count_words(text):\n",
    "    return len(text.split())\n",
    "\n",
    "# Apply the word count function to the 'Text' column\n",
    "df['Word_Count'] = df['Text'].apply(count_words)\n",
    "\n",
    "# Group by 'Label' and sum the word counts\n",
    "word_count_per_class = df.groupby('Label')['Word_Count'].sum().reset_index()\n",
    "\n",
    "# Create a Donut Chart\n",
    "fig = px.pie(word_count_per_class, values='Word_Count', names='Label', title='Word Count per Emotion Class (Donut Chart)', hole=0.4)\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download NLTK stopwords (if not already downloaded)\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Assuming your dataset is already loaded into a DataFrame called `df`\n",
    "# If not, load your data as shown in the previous example\n",
    "\n",
    "# Step 1: Remove URLs\n",
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub('', text)\n",
    "\n",
    "df['Text'] = df['Text'].apply(remove_urls)\n",
    "\n",
    "# Step 2: Remove special characters and punctuation\n",
    "def remove_special_chars(text):\n",
    "    return re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "\n",
    "df['Text'] = df['Text'].apply(remove_special_chars)\n",
    "\n",
    "# Step 3: Remove extra whitespaces\n",
    "def remove_extra_whitespace(text):\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "df['Text'] = df['Text'].apply(remove_extra_whitespace)\n",
    "\n",
    "# Step 4: Remove numeric values\n",
    "def remove_numeric_values(text):\n",
    "    return re.sub(r'\\d+', '', text)\n",
    "\n",
    "df['Text'] = df['Text'].apply(remove_numeric_values)\n",
    "\n",
    "# Step 5: Lowercasing\n",
    "df['Text'] = df['Text'].str.lower()\n",
    "\n",
    "# Step 6: Remove stop words\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "df['Text'] = df['Text'].apply(remove_stopwords)\n",
    "\n",
    "# Step 7: Remove non-alphanumeric characters\n",
    "def remove_non_alphanumeric(text):\n",
    "    return re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "\n",
    "df['Text'] = df['Text'].apply(remove_non_alphanumeric)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 1. Imports\n",
    "# ===============================\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# ===============================\n",
    "# 2. Train / Val / Test split (80 / 10 / 10)\n",
    "# ===============================\n",
    "SEED = 42\n",
    "\n",
    "train_data, temp_data, train_labels, temp_labels = train_test_split(\n",
    "    df[\"Text\"], df[\"Label\"],\n",
    "    test_size=0.20,                 # 80 / 20\n",
    "    random_state=SEED,\n",
    "    stratify=df[\"Label\"]\n",
    ")\n",
    "\n",
    "val_data, test_data, val_labels, test_labels = train_test_split(\n",
    "    temp_data, temp_labels,\n",
    "    test_size=0.50,                 # 10 / 10\n",
    "    random_state=SEED,\n",
    "    stratify=temp_labels\n",
    ")\n",
    "\n",
    "print(\"Train distribution:\\n\", train_labels.value_counts())\n",
    "print(\"Val distribution:\\n\", val_labels.value_counts())\n",
    "print(\"Test distribution:\\n\", test_labels.value_counts())\n",
    "\n",
    "# ===============================\n",
    "# 3. Back-translation setup\n",
    "# ===============================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "en_de_model_name = \"Helsinki-NLP/opus-mt-en-de\"\n",
    "de_en_model_name = \"Helsinki-NLP/opus-mt-de-en\"\n",
    "\n",
    "en_de_tokenizer = MarianTokenizer.from_pretrained(en_de_model_name)\n",
    "en_de_model = MarianMTModel.from_pretrained(en_de_model_name).to(device)\n",
    "en_de_model.eval()\n",
    "\n",
    "de_en_tokenizer = MarianTokenizer.from_pretrained(de_en_model_name)\n",
    "de_en_model = MarianMTModel.from_pretrained(de_en_model_name).to(device)\n",
    "de_en_model.eval()\n",
    "\n",
    "# ===============================\n",
    "# 4. Back-translation function\n",
    "# ===============================\n",
    "def back_translate(texts, max_length=128, batch_size=16):\n",
    "    if len(texts) == 0:\n",
    "        return []\n",
    "\n",
    "    augmented_texts = []\n",
    "\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i + batch_size]\n",
    "\n",
    "        en_inputs = en_de_tokenizer(\n",
    "            batch,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=max_length\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            de_outputs = en_de_model.generate(\n",
    "                **en_inputs,\n",
    "                num_beams=4,\n",
    "                max_length=max_length\n",
    "            )\n",
    "\n",
    "        de_texts = en_de_tokenizer.batch_decode(\n",
    "            de_outputs,\n",
    "            skip_special_tokens=True\n",
    "        )\n",
    "\n",
    "        de_inputs = de_en_tokenizer(\n",
    "            de_texts,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=max_length\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            en_outputs = de_en_model.generate(\n",
    "                **de_inputs,\n",
    "                num_beams=4,\n",
    "                max_length=max_length\n",
    "            )\n",
    "\n",
    "        back_texts = de_en_tokenizer.batch_decode(\n",
    "            en_outputs,\n",
    "            skip_special_tokens=True\n",
    "        )\n",
    "\n",
    "        augmented_texts.extend(back_texts)\n",
    "\n",
    "    return augmented_texts\n",
    "\n",
    "# ===============================\n",
    "# 5. Minority-class augmentation (TRAIN ONLY)\n",
    "# ===============================\n",
    "def augment_minority_classes(train_texts, train_labels, max_aug_per_class=None):\n",
    "    train_texts = train_texts.reset_index(drop=True)\n",
    "    train_labels = train_labels.reset_index(drop=True)\n",
    "\n",
    "    label_counts = train_labels.value_counts()\n",
    "    median_count = int(np.median(label_counts.values))\n",
    "\n",
    "    # Minority classes = below median frequency\n",
    "    minority_classes = label_counts[label_counts < median_count].index.tolist()\n",
    "\n",
    "    augmented_texts = []\n",
    "    augmented_labels = []\n",
    "\n",
    "    for cls in minority_classes:\n",
    "        cls_indices = np.where(train_labels.values == cls)[0]\n",
    "        cls_texts = train_texts.iloc[cls_indices].tolist()\n",
    "\n",
    "        if max_aug_per_class:\n",
    "            cls_texts = cls_texts[:max_aug_per_class]\n",
    "\n",
    "        bt_texts = back_translate(cls_texts)\n",
    "\n",
    "        augmented_texts.extend(bt_texts)\n",
    "        augmented_labels.extend([cls] * len(bt_texts))\n",
    "\n",
    "    # Combine original + augmented (TRAIN ONLY)\n",
    "    train_texts_aug = train_texts.tolist() + augmented_texts\n",
    "    train_labels_aug = train_labels.tolist() + augmented_labels\n",
    "\n",
    "    return train_texts_aug, train_labels_aug\n",
    "\n",
    "# ===============================\n",
    "# 6. Apply augmentation\n",
    "# ===============================\n",
    "train_data_aug, train_labels_aug = augment_minority_classes(\n",
    "    train_data,\n",
    "    train_labels,\n",
    "    max_aug_per_class=2000   # safety cap (optional)\n",
    ")\n",
    "\n",
    "print(\"Original train size:\", len(train_data))\n",
    "print(\"Augmented train size:\", len(train_data_aug))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Distillation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import (\n",
    "    BertTokenizer, BertForSequenceClassification, AlbertForSequenceClassification,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "batch_size = 64\n",
    "epochs_teacher = 10\n",
    "epochs_student = 10\n",
    "initial_lr = 2e-5\n",
    "student_lr = 1e-5\n",
    "T = 1.5\n",
    "alpha = 0.8\n",
    "initial_weight_decay = 1e-2\n",
    "patience = 5\n",
    "max_grad_norm = 1.0\n",
    "label_smoothing = 0.1\n",
    "attn_beta = 0.1\n",
    "max_length = 128\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels = label_encoder.fit_transform(train_df['Label'].values)\n",
    "val_labels   = label_encoder.transform(np.array(val_labels))\n",
    "test_labels  = label_encoder.transform(np.array(test_labels))\n",
    "\n",
    "train_data = train_df['Text'].astype(str).values\n",
    "val_data   = np.array(val_data, dtype=str)\n",
    "test_data  = np.array(test_data, dtype=str)\n",
    "\n",
    "num_labels = len(label_encoder.classes_)\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "class_weights = class_weights / class_weights.mean()\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        text = str(self.texts[item])\n",
    "        label = int(self.labels[item])\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "train_dataset = TextDataset(train_data, train_labels, tokenizer, max_length=max_length)\n",
    "val_dataset   = TextDataset(val_data,   val_labels,   tokenizer, max_length=max_length)\n",
    "test_dataset  = TextDataset(test_data,  test_labels,  tokenizer, max_length=max_length)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=data_collator)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, collate_fn=data_collator)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, collate_fn=data_collator)\n",
    "\n",
    "teacher_model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    num_labels=num_labels,\n",
    "    hidden_dropout_prob=0.3\n",
    ")\n",
    "teacher_model.config.output_attentions = True\n",
    "\n",
    "student_model = AlbertForSequenceClassification.from_pretrained(\n",
    "    'albert-base-v2',\n",
    "    num_labels=num_labels,\n",
    "    output_hidden_states=True,\n",
    "    output_attentions=True\n",
    ")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "teacher_model.to(device)\n",
    "student_model.to(device)\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, class_weights, focal_alpha_scale=1.0, gamma=2.0, label_smoothing=0.1, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.register_buffer(\"class_weights\", class_weights.float())\n",
    "        self.focal_alpha_scale = focal_alpha_scale\n",
    "        self.gamma = gamma\n",
    "        self.label_smoothing = label_smoothing\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        ce = nn.CrossEntropyLoss(reduction='none', label_smoothing=self.label_smoothing)(logits, targets)\n",
    "        pt = torch.exp(-ce)\n",
    "        alpha_y = self.class_weights[targets] * self.focal_alpha_scale\n",
    "        loss = alpha_y * ((1 - pt) ** self.gamma) * ce\n",
    "        return loss.mean() if self.reduction == 'mean' else loss.sum()\n",
    "\n",
    "def validate_model(model, val_loader, criterion=None):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Validation\", leave=False):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            if criterion is not None:\n",
    "                loss = criterion(logits, labels)\n",
    "            else:\n",
    "                loss = nn.CrossEntropyLoss(label_smoothing=label_smoothing)(logits, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_loss = val_loss / len(val_loader)\n",
    "    accuracy = correct / total * 100\n",
    "    print(f\"Validation Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def train_teacher(model, train_loader, val_loader, epochs, lr):\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=initial_weight_decay)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True)\n",
    "    criterion = FocalLoss(class_weights.to(device), focal_alpha_scale=0.25, gamma=2.0, label_smoothing=label_smoothing)\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    trigger_times = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for batch in tqdm(train_loader, desc=f\"Teacher Epoch {epoch+1}/{epochs}\", leave=False):\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            with autocast():\n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "                logits = outputs.logits\n",
    "                loss = criterion(logits, labels)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        accuracy = correct / total * 100\n",
    "        print(f\"Teacher Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "        val_loss, _ = validate_model(model, val_loader, criterion=criterion)\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            trigger_times = 0\n",
    "        else:\n",
    "            trigger_times += 1\n",
    "            if trigger_times >= patience:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "\n",
    "    return model\n",
    "\n",
    "def attention_alignment_loss(teacher_attns, student_attns):\n",
    "    tL = len(teacher_attns)\n",
    "    sL = len(student_attns)\n",
    "    loss = 0.0\n",
    "    count = 0\n",
    "\n",
    "    if tL >= 2 * sL:\n",
    "        for i in range(sL):\n",
    "            t = teacher_attns[2*i]\n",
    "            s = student_attns[i]\n",
    "            h = min(t.size(1), s.size(1))\n",
    "            loss += torch.mean((s[:, :h] - t[:, :h]) ** 2)\n",
    "            count += 1\n",
    "    else:\n",
    "        L = min(tL, sL)\n",
    "        for i in range(L):\n",
    "            t = teacher_attns[i]\n",
    "            s = student_attns[i]\n",
    "            h = min(t.size(1), s.size(1))\n",
    "            loss += torch.mean((s[:, :h] - t[:, :h]) ** 2)\n",
    "            count += 1\n",
    "\n",
    "    return loss / max(count, 1)\n",
    "\n",
    "def train_student_with_kd(teacher_model, student_model, train_loader, val_loader, epochs, lr, temperature, alpha):\n",
    "    optimizer = optim.AdamW(student_model.parameters(), lr=lr, weight_decay=initial_weight_decay)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True)\n",
    "    criterion = FocalLoss(class_weights.to(device), focal_alpha_scale=0.8, gamma=2.0, label_smoothing=label_smoothing)\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    trigger_times = 0\n",
    "\n",
    "    def kd_loss(student_logits, teacher_logits):\n",
    "        s_logp = torch.nn.functional.log_softmax(student_logits / temperature, dim=-1)\n",
    "        t_p    = torch.nn.functional.softmax(teacher_logits / temperature, dim=-1)\n",
    "        return torch.nn.functional.kl_div(s_logp, t_p, reduction='batchmean') * (temperature ** 2)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        student_model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for batch in tqdm(train_loader, desc=f\"Student KD Epoch {epoch+1}/{epochs}\", leave=False):\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                teacher_outputs = teacher_model(input_ids, attention_mask=attention_mask, output_attentions=True)\n",
    "                teacher_logits = teacher_outputs.logits\n",
    "                teacher_attns  = teacher_outputs.attentions\n",
    "\n",
    "            with autocast():\n",
    "                student_outputs = student_model(input_ids, attention_mask=attention_mask, output_attentions=True)\n",
    "                student_logits = student_outputs.logits\n",
    "                student_attns  = student_outputs.attentions\n",
    "\n",
    "                ce_loss = criterion(student_logits, labels)\n",
    "                kd_loss_value = kd_loss(student_logits, teacher_logits)\n",
    "                attn_loss = attention_alignment_loss(teacher_attns, student_attns)\n",
    "\n",
    "                total_loss = alpha * kd_loss_value + (1 - alpha) * ce_loss + attn_beta * attn_loss\n",
    "\n",
    "            scaler.scale(total_loss).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(student_model.parameters(), max_grad_norm)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            running_loss += total_loss.item()\n",
    "            _, predicted = torch.max(student_logits, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        accuracy = correct / total * 100\n",
    "        print(f\"Student KD Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "        val_loss, _ = validate_model(student_model, val_loader, criterion=criterion)\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            trigger_times = 0\n",
    "        else:\n",
    "            trigger_times += 1\n",
    "            if trigger_times >= patience:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "\n",
    "    return student_model\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Testing\", leave=False):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "    accuracy = correct / total * 100\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Test F1 Score: {f1:.4f}\")\n",
    "    print(f\"Test Precision: {precision:.4f}\")\n",
    "    print(f\"Test Recall: {recall:.4f}\")\n",
    "\n",
    "    return accuracy, f1, precision, recall\n",
    "\n",
    "teacher_model = train_teacher(teacher_model, train_loader, val_loader, epochs_teacher, initial_lr)\n",
    "student_model = train_student_with_kd(teacher_model, student_model, train_loader, val_loader, epochs_student, student_lr, T, alpha)\n",
    "\n",
    "print(\"\\nTeacher Model Evaluation:\")\n",
    "evaluate_model(teacher_model, test_loader)\n",
    "\n",
    "print(\"\\nStudent Model Evaluation:\")\n",
    "evaluate_model(student_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_misclassified_examples(model, test_loader):\n",
    "    model.eval()\n",
    "    misclassified_examples = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Collecting Misclassified Examples\", leave=False):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "\n",
    "            for i in range(len(labels)):\n",
    "                if predicted[i] != labels[i]:\n",
    "                    misclassified_examples.append({\n",
    "                        \"text\": tokenizer.decode(\n",
    "                            input_ids[i],\n",
    "                            skip_special_tokens=True\n",
    "                        ),\n",
    "                        \"true_label\": label_encoder.inverse_transform(\n",
    "                            [labels[i].cpu().item()]\n",
    "                        )[0],\n",
    "                        \"predicted_label\": label_encoder.inverse_transform(\n",
    "                            [predicted[i].cpu().item()]\n",
    "                        )[0]\n",
    "                    })\n",
    "\n",
    "    return misclassified_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add text length to the DataFrame\n",
    "misclassified_df['text_length'] = misclassified_df['text'].apply(len)\n",
    "\n",
    "# Plot text length distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(misclassified_df['text_length'], bins=30, kde=True)\n",
    "plt.title('Text Length Distribution for Misclassified Examples')\n",
    "plt.xlabel('Text Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Print a sample of misclassified examples\n",
    "for _, row in misclassified_df.sample(5).iterrows():\n",
    "    print(f\"Text: {row['text']}\")\n",
    "    print(f\"True Label: {row['true_label']}\")\n",
    "    print(f\"Predicted Label: {row['predicted_label']}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(model, test_loader):\n",
    "    model.eval()\n",
    "    all_true_labels = []\n",
    "    all_predicted_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Generating Confusion Matrix\", leave=False):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "\n",
    "            all_true_labels.extend(labels.cpu().numpy())\n",
    "            all_predicted_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(all_true_labels, all_predicted_labels)\n",
    "    class_names = label_encoder.classes_\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.show()\n",
    "\n",
    "# Plot confusion matrix for the student model\n",
    "plot_confusion_matrix(student_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "def generate_classification_report(model, test_loader):\n",
    "    model.eval()\n",
    "    all_true_labels = []\n",
    "    all_predicted_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Generating Predictions\", leave=False):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "\n",
    "            all_true_labels.extend(labels.cpu().numpy())\n",
    "            all_predicted_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # Generate classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(\n",
    "        all_true_labels,\n",
    "        all_predicted_labels,\n",
    "        target_names=label_encoder.classes_,\n",
    "        digits=4\n",
    "    ))\n",
    "    \n",
    "    # Print accuracy\n",
    "    print(f\"Accuracy: {accuracy_score(all_true_labels, all_predicted_labels):.4f}\")\n",
    "    \n",
    "    # Print label mapping\n",
    "    print(\"\\nEmotion Label Mapping:\")\n",
    "    print(dict(enumerate(label_encoder.classes_)))\n",
    "\n",
    "# Example usage for student model\n",
    "print(\"Student Model Evaluation:\")\n",
    "generate_classification_report(student_model, test_loader)\n",
    "\n",
    "# Example usage for teacher model\n",
    "print(\"\\nTeacher Model Evaluation:\")\n",
    "generate_classification_report(teacher_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def generate_misclassification_distribution(model, test_loader, label_encoder):\n",
    "    model.eval()\n",
    "    all_true_labels = []\n",
    "    all_predicted_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Generating Predictions\", leave=False):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "\n",
    "            all_true_labels.extend(labels.cpu().numpy())\n",
    "            all_predicted_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # Create DataFrame for misclassifications\n",
    "    misclassified_df = pd.DataFrame({\n",
    "        'true_label': all_true_labels,\n",
    "        'predicted_label': all_predicted_labels\n",
    "    })\n",
    "\n",
    "    # Create a confusion matrix (cross-tab) of true vs predicted labels\n",
    "    cross_tab = pd.crosstab(misclassified_df['true_label'], misclassified_df['predicted_label'])\n",
    "\n",
    "    # Define the order of classes based on the actual labels in cross_tab\n",
    "    class_order = cross_tab.index.tolist()  # Use the exact labels from cross_tab\n",
    "\n",
    "    # Reorder the cross-tabulation based on the defined class order\n",
    "    cross_tab = cross_tab.loc[class_order, class_order]\n",
    "\n",
    "    # Remove the diagonal (correct predictions) to only show misclassifications\n",
    "    misclassified_tab = cross_tab.copy()\n",
    "    for i in range(len(misclassified_tab)):\n",
    "        misclassified_tab.iloc[i, i] = 0  # Set diagonal to 0 to exclude correct classifications\n",
    "\n",
    "    # Create a grouped bar plot for misclassifications only\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    ax = misclassified_tab.plot(kind='bar', width=0.8, colormap='viridis', figsize=(14, 8))\n",
    "\n",
    "    # Add title and labels\n",
    "    plt.title('Misclassification Distribution: True Classes vs Predicted Classes (Student Model)', fontsize=16, pad=20)\n",
    "    plt.xlabel('True Label', fontsize=14)\n",
    "    plt.ylabel('Count of Misclassifications', fontsize=14)\n",
    "\n",
    "    # Customize legend to show predicted label names\n",
    "    class_names = {0: 'Angry', 1: 'Happy', 2: 'Neutral', 3: 'Sad', 4: 'Surprise'}\n",
    "    predicted_labels = [class_names[i] for i in misclassified_tab.columns]  # Mapping predicted indices to label names\n",
    "    plt.legend(title='Predicted Label', labels=predicted_labels, bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=12)\n",
    "\n",
    "    # Map integer labels to class names for the x-axis\n",
    "    plt.xticks(ticks=range(len(misclassified_tab.index)), labels=[class_names[i] for i in misclassified_tab.index], rotation=45, ha='right', fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "\n",
    "    # Add gridlines for better visualization\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Add data labels on top of bars\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(\n",
    "            f\"{int(p.get_height())}\",  # Display the count as an integer\n",
    "            (p.get_x() + p.get_width() / 2, p.get_height()),  # Position of the label\n",
    "            ha='center', va='bottom',  # Alignment of the label\n",
    "            fontsize=10,  # Font size of the label\n",
    "            color='black'  # Color of the label\n",
    "        )\n",
    "\n",
    "    # Adjust layout to prevent overlapping\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Example usage for student model only\n",
    "print(\"Student Model Evaluation - Misclassification Distribution:\")\n",
    "generate_misclassification_distribution(student_model, test_loader, label_encoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def generate_misclassification_distribution(model, test_loader, label_encoder):\n",
    "    model.eval()\n",
    "    all_true_labels = []\n",
    "    all_predicted_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Generating Predictions\", leave=False):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "\n",
    "            all_true_labels.extend(labels.cpu().numpy())\n",
    "            all_predicted_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # Create DataFrame for misclassifications\n",
    "    misclassified_df = pd.DataFrame({\n",
    "        'true_label': all_true_labels,\n",
    "        'predicted_label': all_predicted_labels\n",
    "    })\n",
    "\n",
    "    # Create a confusion matrix (cross-tab) of true vs predicted labels\n",
    "    cross_tab = pd.crosstab(misclassified_df['true_label'], misclassified_df['predicted_label'])\n",
    "\n",
    "    # Define the order of classes based on the actual labels in cross_tab\n",
    "    class_order = cross_tab.index.tolist()  # Use the exact labels from cross_tab\n",
    "\n",
    "    # Reorder the cross-tabulation based on the defined class order\n",
    "    cross_tab = cross_tab.loc[class_order, class_order]\n",
    "\n",
    "    # Plot grouped bar plot with improved formatting\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    ax = cross_tab.plot(kind='bar', width=0.8, colormap='viridis', figsize=(14, 8))\n",
    "\n",
    "    # Add title and labels\n",
    "    plt.title('Misclassification Distribution: True Classes vs Predicted Classes (Student Model)', fontsize=16, pad=20)\n",
    "    plt.xlabel('True Label', fontsize=14)\n",
    "    plt.ylabel('Count of Misclassifications', fontsize=14)\n",
    "\n",
    "    # Customize legend to show predicted label names\n",
    "    class_names = {0: 'Angry', 1: 'Happy', 2: 'Neutral', 3: 'Sad', 4: 'Surprise'}\n",
    "    predicted_labels = [class_names[i] for i in cross_tab.columns]  # Mapping predicted indices to label names\n",
    "    plt.legend(title='Predicted Label', labels=predicted_labels, bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=12)\n",
    "\n",
    "    # Map integer labels to class names for the x-axis\n",
    "    plt.xticks(ticks=range(len(cross_tab.index)), labels=[class_names[i] for i in cross_tab.index], rotation=45, ha='right', fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "\n",
    "    # Add gridlines for better visualization\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Add data labels on top of bars\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(\n",
    "            f\"{int(p.get_height())}\",  # Display the count as an integer\n",
    "            (p.get_x() + p.get_width() / 2, p.get_height()),  # Position of the label\n",
    "            ha='center', va='bottom',  # Alignment of the label\n",
    "            fontsize=10,  # Font size of the label\n",
    "            color='black'  # Color of the label\n",
    "        )\n",
    "\n",
    "    # Adjust layout to prevent overlapping\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Example usage for student model only\n",
    "print(\"Student Model Evaluation - Misclassification Distribution:\")\n",
    "generate_misclassification_distribution(student_model, test_loader, label_encoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_tsne(model, test_loader):\n",
    "    model.eval()\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Generating t-SNE Features\", leave=False):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            # Extract hidden states (features)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "            hidden_states = outputs.hidden_states[-1]  # Use the last hidden state\n",
    "            cls_embeddings = hidden_states[:, 0, :].cpu().numpy()  # Use [CLS] token embeddings\n",
    "\n",
    "            all_features.extend(cls_embeddings)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    all_features = np.array(all_features)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    # Apply t-SNE\n",
    "    tsne = TSNE(n_components=2, random_state=42, perplexity=30, n_iter=1000)\n",
    "    tsne_results = tsne.fit_transform(all_features)\n",
    "\n",
    "    # Plot t-SNE results\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for label in np.unique(all_labels):\n",
    "        indices = all_labels == label\n",
    "        plt.scatter(tsne_results[indices, 0], tsne_results[indices, 1], label=label_encoder.inverse_transform([label])[0])\n",
    "    plt.title('t-SNE Visualization of Feature Space')\n",
    "    plt.xlabel('t-SNE Dimension 1')\n",
    "    plt.ylabel('t-SNE Dimension 2')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Plot t-SNE for the student model\n",
    "plot_tsne(student_model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
